import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision.utils import save_image
import torchvision.transforms as transforms
import os

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
latent_size = 100
hidden_size = 64
image_size = 128
num_epochs = 100
batch_size = 32
learning_rate = 0.0002

# Custom dataset for product images
product_dataset = ImageFolder(root='product_image/',
                              transform=transforms.Compose([
                                  transforms.Resize((image_size, image_size)),
                                  transforms.ToTensor(),
                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                              ]))
# DataLoader for product images
product_dataloader = DataLoader(product_dataset, batch_size=batch_size, shuffle=True)

# Custom dataset for background images
background_dataset = ImageFolder(root='background_images/',
                                 transform=transforms.Compose([
                                     transforms.Resize((image_size, image_size)),
                                     transforms.ToTensor(),
                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                                 ]))
# DataLoader for background images
background_dataloader = DataLoader(background_dataset, batch_size=batch_size, shuffle=True)

# Generator model
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.ConvTranspose2d(latent_size + 3, hidden_size*8, kernel_size=4, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(hidden_size*8),
            nn.ReLU(True),
            nn.ConvTranspose2d(hidden_size*8, hidden_size*4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size*4),
            nn.ReLU(True),
            nn.ConvTranspose2d(hidden_size*4, hidden_size*2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size*2),
            nn.ReLU(True),
            nn.ConvTranspose2d(hidden_size*2, hidden_size, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size),
            nn.ReLU(True),
            nn.ConvTranspose2d(hidden_size, 3, kernel_size=4, stride=2, padding=1, bias=False),
            nn.Tanh()
        )

    def forward(self, noise, backgrounds):
        noise = noise.view(noise.size(0), latent_size, 1, 1).expand(-1, latent_size, backgrounds.size(2), backgrounds.size(3))
        # Concatenate noise and backgrounds
        gen_input = torch.cat((noise, backgrounds), dim=1)
        return self.model(gen_input)
# Discriminator model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3 + 3, hidden_size, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(hidden_size, hidden_size*2, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size*2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(hidden_size*2, hidden_size*4, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size*4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(hidden_size*4, hidden_size*8, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(hidden_size*8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(hidden_size*8, 1, kernel_size=4, stride=1, padding=0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, inputs, backgrounds):
        # Concatenate inputs and backgrounds
        disc_input = torch.cat((inputs, backgrounds), 1)
        return self.model(disc_input)

# Initialize models
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Loss function
criterion = nn.BCELoss()

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))

# Training loop
total_step = min(len(product_dataloader), len(background_dataloader))
for epoch in range(num_epochs):
    for i, (product_images, _) in enumerate(product_dataloader):
        # Move images to device
        product_images = product_images.to(device)

        # Sample random backgrounds
        background_images, _ = next(iter(background_dataloader))
        background_images = background_images.to(device)

        # Adversarial ground truths
        real_labels = torch.ones(product_images.size(0), 1, device=device)
        fake_labels = torch.zeros(product_images.size(0), 1, device=device)

        # Sample noise
        noise = torch.randn(product_images.size(0), latent_size, device=device)

        # Generate fake images
        gen_images = generator(noise, background_images)

        # Train the discriminator
        optimizer_D.zero_grad()
        real_loss = criterion(discriminator(product_images, background_images), real_labels)
        fake_loss = criterion(discriminator(gen_images.detach(), background_images), fake_labels)
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # Train the generator
        optimizer_G.zero_grad()
        g_loss = criterion(discriminator(gen_images, background_images), real_labels)
        g_loss.backward()
        optimizer_G.step()

        # Print training progress
        if (i+1) % 100 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], "
                  f"Generator Loss: {g_loss.item():.4f}, Discriminator Loss: {d_loss.item():.4f}")

    # Save generated images at the end of each epoch
    if (epoch+1) % 10 == 0:
        save_image(gen_images[:25], f'generated_images_{epoch+1}.png', nrow=5, normalize=True)

